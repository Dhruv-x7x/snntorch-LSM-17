{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMyvlJntnTUYFt04yX3UUrA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IiqIptgrfMNH"},"outputs":[],"source":["!pip install snntorch\n","!pip install tonic"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yP9LW9hwfps9","executionInfo":{"status":"ok","timestamp":1694508415864,"user_tz":-330,"elapsed":20399,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}},"outputId":"95d63adc-336f-4c8a-a4de-e251b80f944b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/snntorch-LSM')"],"metadata":{"id":"cK1StmZKfqa-","executionInfo":{"status":"ok","timestamp":1694508438661,"user_tz":-330,"elapsed":366,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import tonic\n","from tonic import DiskCachedDataset\n","import tonic.transforms as transforms\n","import torch\n","from torch.utils.data import DataLoader\n","\n","import numpy as np\n","from sklearn import linear_model\n","import time\n","\n","#from lsm_weight_definitions import initWeights1\n","#from lsm_models import LSM\n","import lsm_weight_definitions as lsm_wts\n","import lsm_models\n","\n","if __name__ == \"__main__\":\n","\n","    #Load dataset (Using NMNIST here)\n","    sensor_size = tonic.datasets.NMNIST.sensor_size\n","    frame_transform = transforms.Compose([transforms.Denoise(filter_time=3000),\n","                                          transforms.ToFrame(sensor_size=sensor_size,time_window=1000)])\n","\n","    trainset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=True)\n","    testset = tonic.datasets.NMNIST(save_to='./data', transform=frame_transform, train=False)\n","\n","    cached_trainset = DiskCachedDataset(trainset, cache_path='./cache/nmnist/train')\n","    cached_testset = DiskCachedDataset(testset, cache_path='./cache/nmnist/test')\n","\n","    batch_size = 256\n","    trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n","    testloader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False))\n","\n","    #Set device\n","    #device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    print(device)\n","\n","    data, targets = next(iter(trainloader))\n","    flat_data = torch.reshape(data, (data.shape[0], data.shape[1], -1))\n","    print(flat_data.shape)\n","\n","    in_sz = flat_data.shape[-1]\n","\n","    #Set neuron parameters\n","    tauV = 16.0\n","    tauI = 16.0\n","    th = 20\n","    curr_prefac = np.float32(1/tauI)\n","    alpha = np.float32(np.exp(-1/tauI))\n","    beta = np.float32(1 - 1/tauV)\n","\n","    Win, Wlsm = lsm_wts.initWeights1(27, 2, 0.15, in_sz)\n","    N = Wlsm.shape[0]\n","    lsm_net = lsm_models.LSM(N, in_sz, np.float32(curr_prefac*Win), np.float32(curr_prefac*Wlsm), alpha=alpha, beta=beta, th=th).to(device)\n","    lsm_net.eval()\n","    #Run with no_grad for LSM\n","    with torch.no_grad():\n","        start_time = time.time()\n","        for i, (data, targets) in enumerate(iter(trainloader)):\n","            if i%25 == 24:\n","                print(\"train batches completed: \", i)\n","            flat_data = torch.reshape(data, (data.shape[0], data.shape[1], -1)).to(device)\n","            spk_rec = lsm_net(flat_data)\n","            lsm_out = torch.mean(spk_rec, dim=0)\n","            if i==0:\n","                in_train = torch.mean(flat_data, dim=0).cpu().numpy()\n","                lsm_out_train = lsm_out.cpu().numpy()\n","                lsm_label_train = np.int32(targets.numpy())\n","            else:\n","                in_train = np.concatenate((in_train, torch.mean(flat_data, dim=0).cpu().numpy()), axis=0)\n","                lsm_out_train = np.concatenate((lsm_out_train, lsm_out.cpu().numpy()), axis=0)\n","                lsm_label_train = np.concatenate((lsm_label_train, np.int32(targets.numpy())), axis=0)\n","        end_time = time.time()\n","\n","        print(\"running time of training epoch: \", end_time - start_time, \"seconds\")\n","\n","        for i, (data, targets) in enumerate(iter(testloader)):\n","            if i%25 == 24:\n","                print(\"test batches completed: \", i)\n","            flat_data = torch.reshape(data, (data.shape[0], data.shape[1], -1)).to(device)\n","            lsm_net.eval()\n","            spk_rec = lsm_net(flat_data)\n","            lsm_out = torch.mean(spk_rec, dim=0)\n","            if i==0:\n","                in_test = torch.mean(flat_data, dim=0).cpu().numpy()\n","                lsm_out_test = lsm_out.cpu().numpy()\n","                lsm_label_test = np.int32(targets.numpy())\n","            else:\n","                in_test = np.concatenate((in_test, torch.mean(flat_data, dim=0).cpu().numpy()), axis=0)\n","                lsm_out_test = np.concatenate((lsm_out_test, lsm_out.cpu().numpy()), axis=0)\n","                lsm_label_test = np.concatenate((lsm_label_test, np.int32(targets.numpy())), axis=0)\n","\n","    print(lsm_out_train.shape)\n","    print(lsm_out_test.shape)\n","\n","    print(in_train.shape)\n","    print(in_test.shape)\n","\n","    print(\"mean in spiking (train) : \", np.mean(in_train))\n","    print(\"mean in spiking (test) : \", np.mean(in_test))\n","\n","    print(\"mean LSM spiking (train) : \", np.mean(lsm_out_train))\n","    print(\"mean LSM spiking (test) : \", np.mean(lsm_out_test))\n","\n","    print(\"training linear model:\")\n","    clf = linear_model.SGDClassifier(max_iter=10000, tol=1e-6)\n","    clf.fit(lsm_out_train, lsm_label_train)\n","\n","    score = clf.score(lsm_out_test, lsm_label_test)\n","    print(\"test score = \" + str(score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iSeg9V5KfRZZ","executionInfo":{"status":"ok","timestamp":1694511859056,"user_tz":-330,"elapsed":712382,"user":{"displayName":"Anmol Biswas","userId":"10510465683504288355"}},"outputId":"cf22e9b0-4310-4be2-cf2d-618168effe42"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","torch.Size([310, 256, 2312])\n","train batches completed:  24\n","train batches completed:  49\n","train batches completed:  74\n","train batches completed:  99\n","train batches completed:  124\n","train batches completed:  149\n","train batches completed:  174\n","train batches completed:  199\n","train batches completed:  224\n","running time of training epoch:  560.7610261440277 seconds\n","test batches completed:  24\n","(60000, 1000)\n","(10000, 1000)\n","(60000, 2312)\n","(10000, 2312)\n","mean in spiking (train) :  0.0045157326\n","mean in spiking (test) :  0.0045442637\n","mean LSM spiking (train) :  0.1701422\n","mean LSM spiking (test) :  0.17341721\n","training linear model:\n","test score = 0.9599\n"]}]}]}